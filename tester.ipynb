{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook shows a working example of creating an ensemble model using 'binsembler' package\n",
    "# Binsembler is an ensembling technique where the final prediction will be a weighted average of the predicted probabilities by\n",
    "# each individual model. The weights will be the specified evaluation metric such as Accuracy or F1 Score calculated for bins of\n",
    "# specified size (default is 10)\n",
    "# Steps:\n",
    "# Creates an ensemble model using the models input to the function\n",
    "#    1.  Based on the predicted probabilities, create bins of fixed size (say 10)\n",
    "#    2.  For each bin, calculate the Confusion matrix (TP, FP, TN, FN) and calculate other metrics such as Accuracy, AUC, F1 score, Precision, Recall\n",
    "#    3.  Repeat the steps 1 and 2 for other model\n",
    "#    4.  Calculate the final probability as a weighted average of models probabilities\n",
    "#        Select any metric as weights. For e.g. F1 Score\n",
    "#        (m1 F1 score * m1 predicted probability + m2 F1 score * m2 predicted probability)/ (m1 F1 score + m2 F1 score)\n",
    "\n",
    "# The package can ensemble any number of models. User can either give the models and the training data or can \n",
    "# provide the predicted probabilities by each model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the packages\n",
    "from binsembler import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Coefficients: \n",
      "  m1_bins  m1_TP  m1_TN  m1_FP  m1_FN  m1_Accuracy  m1_F1_Score  m1_Precision  \\\n",
      "0   20-30      0      1      0      0          1.0          0.0           0.0   \n",
      "1   40-50      0      0      1      0          0.0          0.0           0.0   \n",
      "2   70-80      1      0      0      0          1.0          1.0           1.0   \n",
      "3   80-90      1      0      0      0          1.0          1.0           1.0   \n",
      "\n",
      "   m1_Recall  m1_AUC  ...  m2_TP m2_TN  m2_FP  m2_FN  m2_Accuracy  \\\n",
      "0        0.0       0  ...      0     1      0      0          1.0   \n",
      "1        0.0       0  ...      1     0      0      0          1.0   \n",
      "2        1.0       0  ...      1     0      0      0          1.0   \n",
      "3        1.0       0  ...      1     0      0      0          1.0   \n",
      "\n",
      "   m2_F1_Score  m2_Precision  m2_Recall  m2_AUC  m2_PR_AUC  \n",
      "0          0.0           0.0        0.0       0          0  \n",
      "1          1.0           1.0        1.0       0          0  \n",
      "2          1.0           1.0        1.0       0          0  \n",
      "3          1.0           1.0        1.0       0          0  \n",
      "\n",
      "[4 rows x 22 columns]\n",
      "   ensmbl_preds  ensmbl_pred_probs  ensmbl_pred_probs0\n",
      "0             1             0.7350              0.2650\n",
      "1             1             0.8998              0.1002\n",
      "2             0             0.1500              0.8500\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Providing Predicted Probabilities by each model\n",
    "\n",
    "# Making up some probabilities\n",
    "y1_preds = [0.25, 0.5, 0.75, 0.9]\n",
    "y2_preds = [0.3, 0.6, 0.8, 0.9]\n",
    "y1_acts = [0, 0, 1, 1]\n",
    "y2_acts = [0, 1, 1, 1]\n",
    "\n",
    "# Initialize Ensembler\n",
    "cl = Classifier()\n",
    "\n",
    "# Train our Ensembler\n",
    "cl.train(y_pred_probs = [y1_preds, y2_preds], y_acts = [y1_acts, y2_acts])\n",
    "print(\"Model Coefficients: \") \n",
    "print(cl.w_)\n",
    "\n",
    "# Predict using Ensembler\n",
    "preds = cl.predict(y_pred_probs=[[0.87, 0.90, 0.1], [0.6, 0.7, 0.2]])\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Umesh.Menon\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Providing model and a training data\n",
    "\n",
    "# create our first simple classification model using Naive Bayes\n",
    "import sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Organize our data\n",
    "label_names = data['target_names']\n",
    "labels = data['target']\n",
    "feature_names = data['feature_names']\n",
    "features = data['data']\n",
    "\n",
    "# Split our data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                          labels,\n",
    "                                                          test_size=0.33,\n",
    "                                                          random_state=42)\n",
    "\n",
    "# Initialize our classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train our classifier\n",
    "model1 = gnb.fit(X_train, y_train)\n",
    "\n",
    "# Create a second model using logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize our classifier\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Train our classifier\n",
    "model2 = logreg.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Coefficients: \n",
      "  m1_bins  m1_Accuracy  m2_Accuracy\n",
      "0    0-10     0.938017     0.995098\n",
      "1   10-20     1.000000     0.947368\n",
      "2   30-40     0.000000     0.500000\n",
      "3   60-70     0.333333     0.600000\n",
      "4   80-90     1.000000     0.333333\n",
      "5  90-100     0.962121     1.000000\n",
      "   ensmbl_preds  ensmbl_pred_probs  ensmbl_pred_probs0\n",
      "0             0           0.091431        9.085692e-01\n",
      "1             1           1.000000        8.953394e-12\n",
      "2             1           0.999997        3.323592e-06\n",
      "3             0           0.002090        9.979101e-01\n",
      "4             0           0.000490        9.995101e-01\n"
     ]
    }
   ],
   "source": [
    "# Initialize Ensembler\n",
    "cl = Classifier()\n",
    "\n",
    "# Train our Ensembler\n",
    "cl.train(models=[model1, model2], targetcols = ['target', 'target'], X_train=X_train, y_train=y_train)\n",
    "print(\"Model Coefficients: \") \n",
    "print(cl.w_[['m1_bins', 'm1_Accuracy', 'm2_Accuracy']])\n",
    "\n",
    "# Predict using Ensembler\n",
    "preds = cl.predict(models=[model1, model2], test_data=X_test)\n",
    "print(preds.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
